#!/usr/bin/env python3
"""
ç»Ÿä¸€è®­ç»ƒå…¥å£
æ”¯æŒ MT5 å’Œ Qwen æ¨¡å‹å¾®è°ƒ
"""
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

import argparse
import sys
from models.mt5 import MT5Trainer
try:
    from models.qwen import QwenTrainer
    QWEN_AVAILABLE = True
except ImportError as e:
    print(f"æ³¨æ„: Qwen æ¨¡å—ä¸å¯ç”¨ ({e})ï¼Œä»…æ”¯æŒ MT5")
    QWEN_AVAILABLE = False

def main():
    parser = argparse.ArgumentParser(description='æ³•å¾‹ç¿»è¯‘æ¨¡å‹å¾®è°ƒ (MT5 / Qwen)')
    
    # æ¨¡å‹é€‰æ‹©
    parser.add_argument('--model_type', default='mt5', choices=['mt5', 'qwen', 'nllb'],
                       help='é€‰æ‹©æ¨¡å‹ç±»å‹: mt5 (Seq2Seq), qwen (LLM) æˆ– nllb (Facebook)')
    parser.add_argument('--base_model', default=None,
                       help='æŒ‡å®šåŸºç¡€æ¨¡å‹è·¯å¾„æˆ–åç§° (ä¾‹å¦‚ Qwen/Qwen3-4B-Instruct-2507)')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--lang_pair', default='zh-ja', choices=['zh-ja', 'zh-en'],
                       help='è¯­è¨€å¯¹')
    parser.add_argument('--train_json', default=None, help='è®­ç»ƒé›†JSONè·¯å¾„')
    parser.add_argument('--test_json', default=None, help='æµ‹è¯•é›†JSONè·¯å¾„')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=4, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=5, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=5e-5, help='å­¦ä¹ ç‡')
    parser.add_argument('--output_dir', default='./checkpoints', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--enable_tensorboard', action='store_true', help='å¯ç”¨ TensorBoard å¯è§†åŒ–')
    parser.add_argument('--max_length', type=int, default=512, help='æœ€å¤§åºåˆ—é•¿åº¦')
    
    args = parser.parse_args()
    
    # é»˜è®¤æ•°æ®è·¯å¾„
    lang_suffix = 'en' if 'en' in args.lang_pair else 'ja'
    
    if not args.train_json:
        args.train_json = f'datasets/my_train_{lang_suffix}.json'
        
    if not args.test_json:
        args.test_json = f'datasets/my_test_{lang_suffix}.json'
    
    print("="*50)
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {args.model_type.upper()}")
    print(f"ğŸ“‚ æ•°æ®é›†: {args.train_json}")
    print("="*50)
    
    if args.model_type == 'qwen':
        if not QWEN_AVAILABLE:
            print("âŒ Qwen ç¯å¢ƒæœªå°±ç»ªï¼Œè¯·å®‰è£… peft, bitsandbytes")
            sys.exit(1)
            
        model_name = args.base_model or "Qwen/Qwen3-4B-Instruct-2507"
        trainer = QwenTrainer(model_name=model_name, max_length=args.max_length)

        # åŠ è½½æ•°æ®
        train_df, test_df = trainer.load_data_from_json(args.train_json, args.test_json, args.lang_pair)
        datasets = {'train': train_df, 'test': test_df, 'lang_pair': args.lang_pair}
        
        # è®­ç»ƒ
        trainer.train(
            datasets, 
            output_dir=f"{args.output_dir}/qwen",
            batch_size=args.batch_size,
            num_epochs=args.epochs,
            learning_rate=args.lr if args.lr != 5e-5 else 2e-4  # LLM LoRA é€šå¸¸å­¦ä¹ ç‡å¤§ä¸€ç‚¹
        )

    elif args.model_type == 'nllb':
        from models.nllb import NLLBTrainer
        # NLLB æµç¨‹
        model_name = args.base_model or "facebook/nllb-200-distilled-600M"
        trainer = NLLBTrainer(model_name=model_name, max_length=args.max_length, enable_tensorboard=args.enable_tensorboard)
        
        train_df, test_df = trainer.load_data_from_json(args.train_json, args.test_json, args.lang_pair)
        datasets = trainer.create_datasets(train_df, test_df, lang_pair=args.lang_pair)
        
        trainer.train(
            datasets,
            output_dir=f"{args.output_dir}/nllb",
            batch_size=args.batch_size,
            num_epochs=args.epochs,
            learning_rate=args.lr
        )
        
    else:
        # MT5 æµç¨‹
        model_name = args.base_model or "K024/mt5-zh-ja-en-trimmed"
        trainer = MT5Trainer(model_name=model_name, max_length=args.max_length, enable_tensorboard=args.enable_tensorboard)
        
        train_df, test_df = trainer.load_data_from_json(args.train_json, args.test_json, args.lang_pair)
        datasets = trainer.create_datasets(train_df, test_df, lang_pair=args.lang_pair)
        
        trainer.train(
            datasets,
            output_dir=f"{args.output_dir}/mt5",
            batch_size=args.batch_size,
            num_epochs=args.epochs,
            learning_rate=args.lr
        )

if __name__ == "__main__":
    main()
